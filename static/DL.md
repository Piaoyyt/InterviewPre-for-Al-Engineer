
# Deep Learning Part
> This is the DL part which aims to summarize the knowledge of the 
> deep learning for Algorithm Interview.

## Main Content
- [1.基本概念](#BasicC)   
   - [优化器](#Optim)
- [2.深度网络模型](#NetModel)
- [3.目标检测](#ObjectDetection)
   - [3.1经典方法](#ClassicalMethod)
   - [3.2常见问题](#CommonProblems)
   - [3.3前沿方法](#FrontierPaper)
- [4.人脸识别]()
- []

## <a id="BasicC"></a>1.基本的概念

### <a id="Optim"></a>1.1.优化器
> **概念**：深度网络模型训练里面负责来控制网络参数更新方向和更新速度的结构。
#### 1.SGD
SGD的全称为Stochastic Gradient Descent,即随机梯度下降，因为SGD里面参数更新的
方向只和当前计算得到的梯度有关，并且参数的更新速率也是一个固定值，属于最早的一种
优化器。
#### 2.SGDM
相比于SGD增加了动量的概念，所谓的动量即考虑了前面的下降方向和下降幅度，让当前时刻的更新
不单单由当前的梯度决定，还受前面的更新方向影响，即动量的体现。
#### 3.Adagrad
自适应的梯度，这里所谓的自适应其实指的是梯度更新里面的学习率自适应，即梯度更新的快慢
程度，加入了不同时刻的梯度平方信息作为调整学习率的依据，使得学习率能够不断变化，这里
是不断的变小。
#### 4.RMSprop
不同于Adagrad里面将梯度平方和的信息作为调整学习率的依据，这样会导致二阶动量会不断的积累，
导致学习率下降的速度过快；这里是采用指数平均公式来计算，避免积累的问题。
#### 5.Adam
在梯度下降方向和梯度下降幅度两方面都加入了指数平均的思想，使得当前参数更新的方向更加的稳定，
并且为了防止在第一次更新的时候梯度更新会偏向于0，在里面还加入了偏置校正。
### <a id="Convolution"></a>1.2 卷积层
#### 1. 普通卷积
> 常规的卷积操作，滑动卷积核的位置，卷积核的维度和输入通道一样，多少种卷积核对应不同的模式，
> 理解为提取不同的特征。
#### 2. 分组卷积
> 将输入通道进行分组，每一个卷积核只需要与一组内的特征图进行卷积即可，使得总体的参数量变为原来的
组数分之一。
#### 3. 深度可分离卷积
>将输入通道的每一个通道作为一组，即分组卷积的特例。
#### 4. 空间可分离卷积
> 将卷积核分成两次分布卷积，即宽和高度上的卷积。
#### 5. 空洞卷积
> 该卷积是在实例分割里面被提出来的，以用于解决一般的卷积感受野不够大，但是提高卷积核大小又会降低
输出的尺寸，并且增大参数量的缺点；因为实例分割要求最后的输出能够对原始图像里面的每个像素点都能够
比较准确的感知。空洞卷积就是在原始的卷积核元素之间插0，变化后的卷积核大小为k + (d - 1) x (k - 1)。

### <a id="Convolution"></a>1.3 池化层
为了选取特征图区域内的显著特征，并降低特征的维度，通过池化整合特征。
#### 1. 平均池化
>取平均值，反向传播的时候直接将值填充到所有的位置进行传播。
#### 2. 最大值池化
>取最大值，反向传播时通过记录的最大值位置去填充最大值
#### 3. 随机池化
>即随机取区域里面的值作为最后的结果。
#### 5. 空间金字塔池化
>即对特征图做不同尺寸的池化操作，因为池化永远输出一个值，所以最后的输出尺寸能够保持一致，和输入的
> 大小无关，在目标检测里面为了减少因为resize导致的目标出现形变问题，引入了SPP操作。
#### 6.全局池化
>即输出只有一个值，即全局上的池化操作。
### <a id="Convolution"></a>1.4 归一化层
#### 1.BN
> 所谓的BN操作，其实就是对于不同样本所对应的特征图，对于同一个通道下的feature map进行归一化，所以一共
会有C也就是通道数这么多个用于归一化的均值和方差。
#### 2.LN
> LN操作，就是对于同一个样本下不同的通道进行归一化，也就是多少个样本就会有多少个不同的均值和方差，所以这里
> 归一化的结果不受样本数目的影响。
#### 3.IN
> IN操作，即实例归一化，将每一个通道里面宽高对应位置的像素值当成个体，去计算H x W这么多像素值的均值和方差，
> 所以一共会有C x B 这么多个均值和方差。
#### 4.GN
> 即将通道进行分组，每一次对组内进行归一化操作，所以LN和IN可以看作是GN的特例。
## <a id="NetModel"></a>2.网络模型
#### 1.LeNet
> LeNet是最早被用来设计进行手写数字识别的网络，由几层卷积层和全连接层组成，结构很简单。
#### 2.AlexNet
> AlexNet是当年用于ImageNet目标检测竞赛的冠军网络，核心点是用了大的卷积核(5、7)，采用了局部响
应归一化（LRN)， 并加入了dropout。
#### 3.VggNet
> 相比于之前的网络结构，核心点在于探索了较深的网络可以提高网络的性能，用小的卷积核代替之前大的卷积核，
并且增加了网络的深度，增加了网络的非线性表达能力。因为两个大小为3的卷积核相当于一个大小为5的卷积核。
#### 4.GoogleNet
> 核心在于Inception模块的设计，该模块通过多个小的卷积核对feature map进行不同的处理，最
后将不同通道数的输出feature map拼接起来，增加了网络的宽度，实际上增加了网络的学习能力， 即每一层
能够学习到的东西更加丰富【1*1的卷积核实现维度的升降维】。 
#### 5.Incepv2-Incepv4
> Inception的不同版本都可以看作是基于googleNet做的改进。
  > - v2：主要加入了BN到网络里面，即批量归一化，对于同一通道的不同样本特征图进行归一化操作，原始论文里面
说降低了训练时的协方差偏移，使得训练能够更快的收敛。
  > - v3: 主要是将普通的卷积进行空间上分解，分解成宽和高度的两步卷积，但是尽管这种可以降低参数量，但是
这两种卷积方式并不能等价，所以如果对于网络性能要求比较好的时候这种方式通常不会采用。
  > - v4: 主要是结合了ResNet里面的残差结构来设计模型。
#### 6.ResNet
  >核心点就是残差块的设计，所谓的残差块其实就相当于一个恒等映射，一般的网络层是将输入直接映射到输出，当网络
  > 较深的时候，如果网络能力下降会使得输出丢失掉很多有用的信息，而残差块的设计直接让输入直接和输出相连，网络
  > 层相当于只学习到了输出和输入之间的差，即使是最差的情况，网络层的输出不会丢失输入的有效信息，这样的设计能
  > 够使得当网络层很深的时候仍然能够学习到有用的东西。
#### 7.SeNet
> SeNet全称为Squeeze and Excitation Net，即先将宽和高压缩成一维的形状，那么每一个通道就得到了各自的值，
> 这个值作为激活前的值经过sigmoid能够得到一个权重，即每个通道的权重，可以看作通道上的注意力，然后和原始的特征图
> 进行相乘。
#### 8.MobileNet
> MobileNet是轻量化网络里面的一个典型代表，轻量化的方式是对于卷积操作进行设计的，即不同于常规的卷积，而是采用
> 分组卷积的形似，将原始特征图的通道进行分组，使得卷积的参数量能够大大降低；同时为了避免分组卷积使得不同通道之间
> 的联系被忽视，在后面又加入了逐像素的卷积操作，即大小为1的卷积核，这种可以融合不同通道之间的信息。
#### 9.ShuffleNet
> 核心点在于shuffle the channel，我们知道分组卷积会造成一个后果，就是不同组的channel之间的信息被忽略了，因
> 为组分好之后，不同组就无法交互了，而shuffle就是提前把通道进行打乱，然后对打乱后的分组，这样就可以解决这个问题。
> 
## <a id="ObjectDetection"></a>3.目标检测篇
### <a id="ClassicalMethod"></a>3.1经典方法
- Two-stage
  #### 1.滑动窗口
  >滑动窗口产生候选框→候选框的特征送入到SVM分类器进行分类、线性回归进行回归
  #### 2.R-CNN
  >不再采用滑动窗口，而是用选择性搜索的方式得到候选区域→不同的区域通过resize传入到网络模型里面得到不同区域的
  > 特征→传入到SVM分类器里面进行分类+线性回归回归。
  #### 3.SPP-Net
  >为了解决resize导致的目标出现形变的问题，引入了SPP即调整金字塔池化，并且先提取整张图的特征，然后在特征层面
  > 去选取候选区域→传入到SVM分类器进行分类+线性回归回归。
  #### 4.Fast-R-CNN
  >借鉴了SPP的思想，采用了ROI池化（即理解为单一尺寸的池化），并且在特征层面去提取候选区域的特征→采用全连接层
  > 进行最后的分类和回归，分类采用softmax、回归采用smooth L1 loss。
  #### 5.Faster-R-CNN
  > 不再是提前生成候选区域，而是结合anchor的设计，让网络一部分RPN检验anchor是否是背景还是非背景，然后将
  检验为非背景的部分传入后面的分类回归网络进行最后的目标检测和回归，整体上看已经很接近one-stage的设计思路
  > 了，即尽可能将候选框提出和检测流程融到一块。
- One-stage
  #### 1.Yolo
  > 将待检测的图片划分成等大的网格，每个网格经过深度网络(后面是两层全连接层+reshape构成)映射到输出feature map的一个点上，该点的不同通道
  > 存储了网格里面是否存在目标的信息，在原论文的设计里面，每一个网格负责预测两个目标（其实实际里面更加简化了，
  > 即这两个目标默认是同一个），所以yolo里面实际的检测框数目很少，即S x S x 2，并且实际的目标只能有S x S个，所以
  > yolo对于那些在同一个网格里面出现多个目标的情况检测很差。
  #### 2.SSD
  > 采用深度网络模型VGG19作为特殊提取backbone部分，不过将全连接层换成了全卷积（全连接会损失空间上的信息），同时对于不同层上的
  > 特征图抽取出来分别来预测各个点上的框（每个点上会设默认的box，预测默认的框之间的偏差即可)。
  #### 3.Yolov2
  > yolo系列里面开始引入anchor的方法，使得能够检测的框的数目大大增加，；网络上采用了darknet19，并且将低层的特征和高层的特征进行
  > 融合，使得最后对小目标的检测效果更好。
  #### 4.Yolov3
  > 网络上采用了darknet53，并且加入了FPN的操作，将高层的特征通过上采样和低层的特征进行融合，使得高层的特征包含的信息更加丰富。
  > 
  #### 5.Yolov4
  > 网络结构采用了CSPDarkNet53+Neck（SPPNet+PAN）+yolov3head；框的回归采用了CIOU； 加入了很多的训练技巧：
     数据增强：Mosaic数据增强，即对四张图像进行随机的缩放、裁剪和排布，多张图像的融合；
     数据不平衡问题：hard负实例挖掘、在线困难实例挖掘，焦点丢失、标签平滑、知识蒸馏；
     正则化：DropPath、DropBlock；
     模拟物体遮挡：随机的选择部分矩形区域、在特征图上dropblock。
  #### 6.Yolov5
  > 网络结构增加了Focus操作，即切片操作； 自适应的锚框的计算，非预先选定，而是在训练过程中同步迭代； 自适应图片的缩放：即测试的时候采用缩减黑
  > 边的方式，而不是传统直接填充，分别求出长宽的缩放比例，并找到最小值；按照最小缩放比例对图像做同性缩放；padding到想要的尺寸。 
  > 其实就是先resize再padding，这样填充黑色比较少。
### <a id="CommonProblems"></a>3.2常见问题
#### 1.正负样本的划分方式以及为什么让一个gt对应多个正anchor？
> 1.正样本就是用来学习anchor(先验框)怎么回归的；2.关于正样本的选取，不同的算法设定的策略有所不同，对于yolov3,先判断物体中心点落在哪个网格内，然后计算目标框(gt)与该网格内所有anchor的iou,
取iou最大的那个为正样本；对于faster_rcnn，首先计算每一个anchor与目标框的iou,如果超过正样本阈值则设定为正样本，然后对每一个目标框将最大iou的anchor设置为正样本（此时iou可能小于正样本阈值），
保证每一个目标框最少有一个正样本与其匹配；3.每一个gt框匹配多个正样本，能够使模型学习的更充分，二阶段检测算法比一阶段算法精度更高，在一定程度上就是因为二阶段检测算法能够匹配更多的正样本以及设置更
好的正负样本比例，每个gt框只取对应一个IOU最大的正样本也可以，只是可能会影响模型的精度．
### <a id="FrontierPaper"></a>3.3前沿思想
- [yolox](https://zhuanlan.zhihu.com/p/392221567)
  > 1、Decoupled head(预测分支解耦):相比于yolov3到v5，其中的分类和回归都是共享一个特征，即非解耦的方式得到，yolox里面采用解耦的方式分别来预测
  > 框的类别和回归坐标。  
  > 2、强大的数据增强:添加Mosaic（将图片进行随机的旋转、裁剪、拼接）和MixUp（两张图以一定的比例对rgb值进行混合，同时需要模型预测出原本两张图中所有的目标）。  
  > 3、Anchor-free：使用anchor时，为了调优模型，需要对数据聚类分析，确定最优锚点，缺乏泛化性；增加了检测头复杂度，增加了每幅图像预测数量。
  > 使用ancho-freer可以减少调整参数数量，减少涉及的使用技巧。  
  > 4、[SiamOTA:](https://zhuanlan.zhihu.com/p/392221567) 其实就是正样本的选择方式，有的是直接将gt所在的那个格子中所有的预测框与gt计算
  > 取最高的作为正样本（yolov3）;有的是取所在网格一定半径的格子来计算得到多个正样本；这里anchor-free下每一个特征图只预测一组anchor，而SiamOta的
  > 核心就在于对于不同的gt，我们去计算出前10个损失最小的框，然后将这些框的IOU求和，求和的结果就是最后要选择的正样本数量，即对于不同gt选不同的正样本数量。
- [yolov6](https://tech.meituan.com/2022/06/23/yolov6-a-fast-and-accurate-target-detection-framework-is-opening-source.html)
  >统一设计了更高效的 Backbone 和 Neck ：受到硬件感知神经网络设计思想的启发，基于 RepVGG style[4] 设计了可重参数化、更高效的骨干网络 EfficientRep Backbone 和 Rep-PAN Neck。
  优化设计了更简洁有效的 Efficient Decoupled Head，在维持精度的同时，进一步降低了一般解耦头带来的额外延时开销。
在训练策略上，我们采用Anchor-free 无锚范式，同时辅以 SimOTA 标签分配策略以及 SIoU 边界框回归损失来进一步提高检测精度。
- [yolov7](https://arxiv.org/abs/2207.02696)
  > 主要在几个方面做了改进：1.模型的结构重参数化，即将原来训练中的参数在推理的时候转化为等效的另一组基本可以等效的参数，减少网络结构的复杂度，本文研究了
  > 如何高效的去替换；2.针对网络的参数提出了扩展和复合缩放，高效利用参数。
## <a id="FaceRecognition"></a>4.人脸识别篇
## <a id=""></a>5.